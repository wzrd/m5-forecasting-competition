{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/data_science/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "from pylab import rcParams\n",
    "import time\n",
    "from  datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing, metrics\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "\n",
    "register_matplotlib_converters()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "def display_missing(df):    \n",
    "    for col in df.columns.tolist():  \n",
    "        if df[col].isnull().sum() != 0:\n",
    "            print('{} column missing values: {}'.format(col, df[col].isnull().sum()))\n",
    "    print('\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Loading data grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_GRID_INPUT_DIR = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n"
     ]
    }
   ],
   "source": [
    "print('Loading the data...')\n",
    "\n",
    "data = pd.read_pickle(f'{DATA_GRID_INPUT_DIR}/m5_data_model2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Init variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 28 # Prediction horizon\n",
    "max_lags = 65 # Max lags used\n",
    "TRAINING_LAST_DAY_NUM = 1913 # Last day for training data\n",
    "FIRST_PRED_DAY = datetime(2016,4, 25) # First prediction day\n",
    "FIRST_LOADING_DAY = datetime(2013, 4,7) # First day for training\n",
    "FIRST_LOADING_DAY_NUM = 800\n",
    "SEED = 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Cuting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine first needed day for training\n",
    "# data = data.loc[data['date'] >= FIRST_LOADING_DAY] # So we will have space for lag and rolling features\n",
    "# gc.collect()\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Computing weights (simulating WMRSSE cost function)\n",
    "\n",
    "We set weights for training samples, based on competition's weighting methodology. It is hard to simulate it fully, \n",
    "but we try to select more valuable items, based on sales for last 28 days in train period. We use agregated sales for \n",
    "each state and department and then compute weights based on these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting last 28 days for calculations\n",
    "last_28d = data.loc[data.date>='2016-03-28']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convert 'sales' column to float32, \n",
    "# so the sum() number will fit into its range\n",
    "last_28d['sales'] = last_28d['sales'].astype(np.float32)\n",
    "total_by_state_dept = last_28d.groupby(['state_id', 'dept_id'])['sales'].sum().reset_index(name='total_by_state_dept')\n",
    "total_by_id = last_28d.groupby(['item_id', 'state_id', 'dept_id'])['sales'].sum().reset_index(name='total_by_id')\n",
    "last_28d = pd.merge(last_28d, total_by_state_dept, on=['state_id', 'dept_id'])\n",
    "last_28d = pd.merge(last_28d, total_by_id, on=['item_id', 'state_id', 'dept_id'])\n",
    "last_28d['weights'] = last_28d['total_by_id'] / last_28d['total_by_state_dept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale weights to have more effect from value in training\n",
    "last_28d['weights'] *= 10\n",
    "\n",
    "# Because CA items have more weight overall, \n",
    "# we also multiply them by 1.6 (based on weights from GitHub)\n",
    "# TODO: If it will work, compute these values in pandas\n",
    "last_28d.loc[last_28d['state_id'] == 0, 'weights'] *= 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a23fa8190>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD7CAYAAACbtbj+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAXkUlEQVR4nO3cf0zU9+HH8dfhIauFxeruxBJrlm6xm0btRjO7NcfcVg52nEyqSYVIk6bB2c0619AhGJhtXI2lapYWUpcly1qblnWVmwZOXRYwDc2mbNGwkK7rxLVS4RBWfkzwgM/3j8b7inW+7/h18PH5SAj5vO/z+dz7xRFed+/jPg7LsiwBAHALCfGeAABg5qMsAABGlAUAwIiyAAAYURYAACPKAgBgRFkAAIyc8Z7AVOnpGdDo6Pg+QrJwYbIuX+6f5BnFlx0zSfbMZcdMkj1z2SlTQoJDd9115/+83bZlMTpqjbssrh1vN3bMJNkzlx0zSfbMZcdMN8MyFADAiLIAABhRFgAAI8oCAGBEWQAAjCgLAIARZQEAMLLt5ywm4mp4RC5XyrTf7+DQsPp6r0z7/QKACWVxE3MT58j/dGDa7/foi7nqm/Z7BQAzlqEAAEaUBQDAiLIAABhRFgAAI8oCAGBEWQAAjCgLAIARZQEAMKIsAABGlAUAwIiyAAAYURYAACPKAgBgRFkAAIwoCwCAEWUBADCiLAAARpQFAMCIsgAAGFEWAAAjygIAYERZAACMKAsAgBFlAQAwoiwAAEZRlcVLL70kn88nn8+nffv2SZKamprk9/uVmZmpAwcORPZtbW1VXl6evF6vysrKNDw8LElqb29XQUGBsrKytHXrVg0MDEiSent7VVRUpOzsbBUUFCgUCkmSrl69quLiYmVnZ2v9+vX64IMPJjU4ACB6xrJoamrSO++8oyNHjqi2tlZ///vfdezYMZWWlqqqqkp1dXVqaWlRY2OjJKm4uFjl5eU6fvy4LMtSTU2NJGn37t3Kz89XMBjUihUrVFVVJUk6ePCg0tPTVV9fr40bN2rPnj2SpFdffVV33HGH6uvrVVpaqp07d07VzwAAYGAsC5fLpZKSEs2dO1eJiYm699571dbWpqVLl2rJkiVyOp3y+/0KBoO6ePGiBgcHtXr1aklSXl6egsGgwuGwTp8+La/XO2ZckhoaGuT3+yVJOTk5OnXqlMLhsBoaGrRu3TpJ0gMPPKDu7m61t7dPyQ8BAHBrxrL48pe/HPnj39bWpvr6ejkcDrlcrsg+brdbHR0d6uzsHDPucrnU0dGhnp4eJScny+l0jhmXNOYYp9Op5ORkdXd33/Rcly5dmoTIAIBYOaPd8f3339eWLVv0zDPPaM6cOWpra4vcZlmWHA6HRkdH5XA4PjN+7fv1bty+/piEhITPHHNtPFoLFyZHve9M4nKlzMpzx5Mdc9kxk2TPXHbMdDNRlUVzc7OeeuoplZaWyufz6S9/+UvkjWhJCoVCcrvdSk1NHTPe1dUlt9utBQsWqK+vTyMjI5ozZ05kf+nTVyVdXV1KTU3V8PCwBgYGNH/+fC1atEidnZ265557xpwrWpcv92t01Ip6/+vF88EPhfqm5LwuV8qUnTue7JjLjpkke+ayU6aEBMctn2Qbn6p//PHH+tGPfqTKykr5fD5J0qpVq3T+/HlduHBBIyMjOnbsmDwej9LS0pSUlKTm5mZJUiAQkMfjUWJiotLT01VXVydJqq2tlcfjkSRlZGSotrZWklRXV6f09HQlJiYqIyNDgUBAknTmzBklJSXp7rvvnsCPAgAwXsZXFr/+9a81NDSkvXv3RsYeffRR7d27V9u2bdPQ0JAyMjKUlZUlSaqsrNSuXbvU39+v5cuXq7CwUJJUUVGhkpISVVdXa/Hixdq/f78kafv27SopKZHP51NKSooqKyslSZs3b1Z5ebl8Pp/mzp0b+ZddAMD0c1iWNb61mhluostQ/qcDkzwjs6Mv5rIMFSM75rJjJsmeueyUacLLUAAAUBYAACPKAgBgRFkAAIwoCwCAEWUBADCiLAAARpQFAMCIsgAAGFEWAAAjygIAYERZAACMKAsAgBFlAQAwoiwAAEaUBQDAiLIAABhRFgAAI8oCAGBEWQAAjCgLAIARZQEAMKIsAABGlAUAwIiyAAAYURYAACPKAgBgRFkAAIwoCwCAEWUBADCiLAAARpQFAMCIsgAAGFEWAAAjygIAYBR1WfT39ysnJ0cfffSRJGnnzp3KzMxUbm6ucnNzdfLkSUlSU1OT/H6/MjMzdeDAgcjxra2tysvLk9frVVlZmYaHhyVJ7e3tKigoUFZWlrZu3aqBgQFJUm9vr4qKipSdna2CggKFQqFJCw0AiE1UZXH27Flt2rRJbW1tkbGWlha99tprCgQCCgQCevjhhzU4OKjS0lJVVVWprq5OLS0tamxslCQVFxervLxcx48fl2VZqqmpkSTt3r1b+fn5CgaDWrFihaqqqiRJBw8eVHp6uurr67Vx40bt2bNnkqMDAKIVVVnU1NSooqJCbrdbknTlyhW1t7ertLRUfr9fv/zlLzU6Oqpz585p6dKlWrJkiZxOp/x+v4LBoC5evKjBwUGtXr1akpSXl6dgMKhwOKzTp0/L6/WOGZekhoYG+f1+SVJOTo5OnTqlcDg86T8AAICZM5qdbnxW39XVpTVr1qiiokIpKSnasmWL3nrrLc2bN08ulyuyn9vtVkdHhzo7O8eMu1wudXR0qKenR8nJyXI6nWPGJY05xul0Kjk5Wd3d3Vq0aNHEEgMAYhZVWdxoyZIlevnllyPbmzdvVm1trbxerxwOR2Tcsiw5HA6Njo7edPza9+vduH39MQkJ0b8fv3BhctT7ziQuV8qsPHc82TGXHTNJ9sxlx0w3M66yeO+999TW1hZZPrIsS06nU6mpqWPeiA6FQnK73Z8Z7+rqktvt1oIFC9TX16eRkRHNmTMnsr/06auSrq4upaamanh4WAMDA5o/f37Uc7x8uV+jo9Z44sX1wQ+F+qbkvC5XypSdO57smMuOmSR75rJTpoQExy2fZI/rX2cty9IvfvELffLJJwqHw3rzzTf18MMPa9WqVTp//rwuXLigkZERHTt2TB6PR2lpaUpKSlJzc7MkKRAIyOPxKDExUenp6aqrq5Mk1dbWyuPxSJIyMjJUW1srSaqrq1N6eroSExPHM10AwASN65XFfffdp6KiIm3atEnDw8PKzMxUTk6OJGnv3r3atm2bhoaGlJGRoaysLElSZWWldu3apf7+fi1fvlyFhYWSpIqKCpWUlKi6ulqLFy/W/v37JUnbt29XSUmJfD6fUlJSVFlZORl5AQDj4LAsa3xrNTPcRJeh/E8HJnlGZkdfzGUZKkZ2zGXHTJI9c9kp05QsQwEAbi+UBQDAiLIAABhRFgAAI8oCAGBEWQAAjCgLAIARZQEAMKIsAABGlAUAwIiyAAAYURYAACPKAgBgRFkAAIwoCwCAEWUBADCiLAAARpQFAMCIsgAAGFEWAAAjygIAYERZAACMKAsAgBFlAQAwoiwAAEaUBQDAiLIAABhRFgAAI8oCAGBEWQAAjCgLAIARZQEAMKIsAABGlAUAwIiyAAAYRVUW/f39ysnJ0UcffSRJampqkt/vV2Zmpg4cOBDZr7W1VXl5efJ6vSorK9Pw8LAkqb29XQUFBcrKytLWrVs1MDAgSert7VVRUZGys7NVUFCgUCgkSbp69aqKi4uVnZ2t9evX64MPPpjU0ACA2BjL4uzZs9q0aZPa2tokSYODgyotLVVVVZXq6urU0tKixsZGSVJxcbHKy8t1/PhxWZalmpoaSdLu3buVn5+vYDCoFStWqKqqSpJ08OBBpaenq76+Xhs3btSePXskSa+++qruuOMO1dfXq7S0VDt37pyK7ACAKBnLoqamRhUVFXK73ZKkc+fOaenSpVqyZImcTqf8fr+CwaAuXryowcFBrV69WpKUl5enYDCocDis06dPy+v1jhmXpIaGBvn9fklSTk6OTp06pXA4rIaGBq1bt06S9MADD6i7u1vt7e2Tnx4AEBWnaYdrz/av6ezslMvlimy73W51dHR8Ztzlcqmjo0M9PT1KTk6W0+kcM37juZxOp5KTk9Xd3X3Tc126dEl33333BKICAMbLWBY3Gh0dlcPhiGxbliWHw/E/x699v96N29cfk5CQ8Jljro3HYuHC5Jj2nylcrpRZee54smMuO2aS7JnLjpluJuaySE1NjbwRLUmhUEhut/sz411dXXK73VqwYIH6+vo0MjKiOXPmRPaXPn1V0tXVpdTUVA0PD2tgYEDz58/XokWL1NnZqXvuuWfMuWJx+XK/RketWONJiu+DHwr1Tcl5Xa6UKTt3PNkxlx0zSfbMZadMCQmOWz7JjvlfZ1etWqXz58/rwoULGhkZ0bFjx+TxeJSWlqakpCQ1NzdLkgKBgDwejxITE5Wenq66ujpJUm1trTwejyQpIyNDtbW1kqS6ujqlp6crMTFRGRkZCgQCkqQzZ84oKSmJJSgAiKOYX1kkJSVp79692rZtm4aGhpSRkaGsrCxJUmVlpXbt2qX+/n4tX75chYWFkqSKigqVlJSourpaixcv1v79+yVJ27dvV0lJiXw+n1JSUlRZWSlJ2rx5s8rLy+Xz+TR37lzt27dvsvICAMbBYVnW+NZqZriJLkP5nw5M8ozMjr6YyzJUjOyYy46ZJHvmslOmSV+GAgDcfigLAIARZQEAMKIsAABGlAUAwIiyAAAYURYAACPKAgBgRFkAAIwoCwCAEWUBADCiLAAARpQFAMCIsgAAGFEWAAAjygIAYERZAACMKAsAgBFlAQAwoiwAAEaUBQDAiLIAABhRFgAAI8oCAGBEWQAAjCgLAIARZQEAMKIsAABGlAUAwIiyAAAYURYAACPKAgBgRFkAAIwoCwCAEWUBADByTuTgzZs3q7u7W07np6d59tln9e9//1vV1dUaHh7WY489poKCAklSU1OTnn/+eQ0NDSk7O1s7duyQJLW2tqqsrEwDAwNKT0/X7t275XQ61d7eruLiYl2+fFlf/OIXVVlZqTvvvHOCcQEA4zHuVxaWZamtrU2BQCDylZqaqgMHDuj1119XbW2t3nzzTf3zn//U4OCgSktLVVVVpbq6OrW0tKixsVGSVFxcrPLych0/flyWZammpkaStHv3buXn5ysYDGrFihWqqqqanMQAgJiNuyz+9a9/SZIef/xxrVu3Tq+99pqampq0Zs0azZ8/X/PmzZPX61UwGNS5c+e0dOlSLVmyRE6nU36/X8FgUBcvXtTg4KBWr14tScrLy1MwGFQ4HNbp06fl9XrHjAMA4mPcZdHb26sHH3xQL7/8sn7zm9/ojTfeUHt7u1wuV2Qft9utjo4OdXZ2RjXucrnU0dGhnp4eJScnR5a3ro0DAOJj3O9Z3H///br//vsj2xs2bNDzzz+vrVu3RsYsy5LD4dDo6KgcDkfU49e+X+/GbZOFC5NjjTQjuFwps/Lc8WTHXHbMJNkzlx0z3cy4y+LMmTMKh8N68MEHJX36hz4tLU2hUCiyTygUktvtVmpqalTjXV1dcrvdWrBggfr6+jQyMqI5c+ZE9o/F5cv9Gh21xpUtng9+KNQ3Jed1uVKm7NzxZMdcdswk2TOXnTIlJDhu+SR73MtQfX192rdvn4aGhtTf368jR47ohRde0Lvvvqvu7m5duXJFJ06ckMfj0apVq3T+/HlduHBBIyMjOnbsmDwej9LS0pSUlKTm5mZJUiAQkMfjUWJiotLT01VXVydJqq2tlcfjGe9UAQATNO5XFmvXrtXZs2f1gx/8QKOjo8rPz9fXv/517dixQ4WFhQqHw9qwYYNWrlwpSdq7d6+2bdumoaEhZWRkKCsrS5JUWVmpXbt2qb+/X8uXL1dhYaEkqaKiQiUlJaqurtbixYu1f//+SYgLABgPh2VZ41urmeEmugzlfzowyTMyO/piLstQMbJjLjtmkuyZy06ZpmwZCgBw+6AsAABGlAUAwIiyAAAYURYAACPKAgBgRFkAAIwoCwCAEWUBADCiLAAARpQFAMCIsgAAGFEWAAAjygIAYERZAACMKAsAgBFlAQAwoiwAAEaUBQDAiLIAABhRFgAAI8oCAGBEWQAAjCgLAIARZQEAMKIsAABGznhPAP/vanhELlfKlJ3/VuceHBpWX++VKbtvALMbZTGDzE2cI//Tgbjc99EXc9UXl3sGMBuwDAUAMKIsAABGlAUAwIiyAAAYURYAACPKAgBgRFkAAIwoCwCA0Yz+UN7Ro0dVXV2t4eFhPfbYYyooKIj3lGxrqj89/r/wyXFgdpixZdHR0aEDBw7o7bff1ty5c/Xoo4/qG9/4hr70pS/Fe2q2FK9Pj/PJcWB2mLFl0dTUpDVr1mj+/PmSJK/Xq2AwqB//+MdRHZ+Q4JjQ/bvvumNCx8+2+43XfU/GK5rxHD80NKz+/sEJ3e9Umujv70xlx1x2yWTK4bAsy5qmucTklVde0X//+1/t2LFDkvS73/1O586d03PPPRfnmQHA7WfGvsE9Ojoqh+P/m86yrDHbAIDpM2PLIjU1VaFQKLIdCoXkdrvjOCMAuH3N2LL45je/qXfffVfd3d26cuWKTpw4IY/HE+9pAcBtaca+wb1o0SLt2LFDhYWFCofD2rBhg1auXBnvaQHAbWnGvsENAJg5ZuwyFABg5qAsAABGlAUAwIiyAAAY3bZlcfToUX3/+99XZmamDh8+/JnbW1tblZeXJ6/Xq7KyMg0PD8dhlrEz5brmmWee0dtvvz2NM5sYU64//vGPys3N1bp16/Tkk0/qk08+icMsY2PKdPLkSfn9fvl8PpWUlOjq1atxmGVsov39a2ho0He+851pnNnEmHK99NJLWrt2rXJzc5Wbm3vL7LOWdRu6dOmStXbtWqunp8caGBiw/H6/9f7774/Zx+fzWX/7298sy7KsnTt3WocPH47HVGMSTa5Lly5ZW7ZssVauXGn9/ve/j9NMY2PK1dfXZ33rW9+yLl26ZFmWZR08eNB67rnn4jXdqJgyDQwMWA899JAVCoUsy7Ksn/zkJ9Ybb7wRr+lGJZrfP8uyrFAoZGVlZVlr166NwyxjF02uLVu2WH/961/jNMPpcVu+srj+IoXz5s2LXKTwmosXL2pwcFCrV6+WJOXl5Y25faYy5ZI+fYb03e9+V9nZ2XGaZexMucLhsCoqKrRo0SJJ0rJly/Txxx/Ha7pRMWWaN2+e/vSnP+kLX/iCrly5osuXL+vzn/98HGdsFs3vnyTt2rUr6guCzgTR5GppadErr7wiv9+vZ599VkNDQ3Ga7dS5Lcuis7NTLpcrsu12u9XR0fE/b3e5XGNun6lMuSTpiSee0MaNG6d7ahNiynXXXXfp4YcfliQNDg7q0KFD+t73vjft84xFNI9VYmKiGhsb9e1vf1s9PT166KGHpnuaMYkm029/+1t99atf1apVq6Z7euNmyjUwMKCvfOUrKi4u1pEjR9Tb26uqqqp4THVK3ZZlYbpI4Wy9iOFsnbdJtLn6+vpUVFSk++67T+vXr5/OKcYs2kwZGRn685//rLVr1+rnP//5NM4wdqZM//jHP3TixAk9+eST8ZjeuJly3XnnnfrVr36le++9V06nU48//rgaGxvjMdUpdVuWhekihTfe3tXVNSsuYmjXiy9Gk6uzs1P5+flatmyZ9uzZM91TjJkp03/+8x+98847kW2/36/33ntvWucYK1OmYDCoUCikRx55REVFRZHHbKYz5Wpvb9dbb70V2bYsS07njL2S0rjdlmVhukhhWlqakpKS1NzcLEkKBAKz4iKGdr34oinXyMiIfvjDHyo7O1tlZWWz4tWUKZNlWSouLlZ7e7ukT//Qfu1rX4vXdKNiyvTUU0/p+PHjCgQCOnTokNxut15//fU4zjg6plyf+9zn9MILL+jDDz+UZVk6fPhwZFnUVuL1znq8/eEPf7B8Pp+VmZlpHTp0yLIsy3riiSesc+fOWZZlWa2trdYjjzxieb1e66c//ak1NDQUz+lGzZTrmp/97Gez5r+hLOvWuU6cOGEtW7bMWrduXeSrtLQ0zjM2Mz1WJ0+etHJyciy/32/t2LHD6u3tjed0oxLt79+HH344a/4byrLMuYLBYOT2kpKSWfP3IhZcSBAAYHRbLkMBAGJDWQAAjCgLAIARZQEAMKIsAABGlAUAwIiyAAAYURYAAKP/A6chFaWZPLl3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "last_28d.loc[last_28d['state_id'] == 1, 'weights'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504171.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_28d.loc[last_28d['state_id'] == 0, 'sales'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     84\n",
       "item_id                84\n",
       "dept_id                84\n",
       "store_id               84\n",
       "cat_id                 84\n",
       "state_id               84\n",
       "d                      84\n",
       "sales                  84\n",
       "date                   84\n",
       "wm_yr_wk               84\n",
       "weekday                84\n",
       "wday                   84\n",
       "month                  84\n",
       "year                   84\n",
       "event_name_1           84\n",
       "event_type_1           84\n",
       "event_name_2           84\n",
       "event_type_2           84\n",
       "snap_CA                84\n",
       "snap_TX                84\n",
       "snap_WI                84\n",
       "sell_price             84\n",
       "total_by_state_dept    84\n",
       "total_by_id            84\n",
       "weights                84\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_28d.loc[last_28d['weights']>0.9].count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_28d.loc[last_28d['total_by_id'] > 1000,'total_by_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_t{lag}\" for lag in lags ]\n",
    "\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        df[lag_col] = df[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag).astype(np.float16)\n",
    "\n",
    "    wins = [7, 28]\n",
    "    for win in wins :\n",
    "        for lag,lag_col in zip(lags, lag_cols):\n",
    "            df[f\"rmean_{lag}_{win}\"] = df[[\"id\", lag_col]].groupby(\"id\")[lag_col].transform(lambda x : x.rolling(win).mean()).astype(np.float16)\n",
    "               \n",
    "    # Adding lagged and rolling features\n",
    "#     df_grpby_id_sales = df[[\"id\",\"sales\"]].groupby([\"id\"])[\"sales\"]\n",
    "#     for val in [1, 2, 3, 4, 5, 6, 7, 28]:\n",
    "#         df[f\"lag_t{val}\"] = df_grpby_id_sales.shift(val).astype(np.float16)\n",
    "\n",
    "#     SHIFT_DAYS = 1 # So we make this features starting from previous day\n",
    "#     for val in [7, 14, 28]:\n",
    "#         df[f\"rolling_mean_t{val}\"] = df_grpby_id_sales.transform(lambda x: x.shift(SHIFT_DAYS).rolling(val).mean()).astype(np.float16)\n",
    "#         df[f\"rolling_std_t{val}\"] = df_grpby_id_sales.transform(lambda x: x.shift(SHIFT_DAYS).rolling(val).std()).astype(np.float16)        \n",
    "#         df[f\"rolling_max_t{val}\"] = df_grpby_id_sales.transform(lambda x: x.shift(SHIFT_DAYS).rolling(val).max()).astype(np.float16)\n",
    "\n",
    "    # Adding price related features\n",
    "#     PRICE_WINDOW = 60\n",
    "#     df_grpby_id_sell_price = df[['id','sell_price']].groupby([\"id\"])[\"sell_price\"]\n",
    "#     df['price_max_t60'] = df_grpby_id_sell_price.transform(lambda x: x.rolling(PRICE_WINDOW).max()).astype(np.float16)\n",
    "#     df['price_min_t60'] = df_grpby_id_sell_price.transform(lambda x: x.rolling(PRICE_WINDOW).min()).astype(np.float16)\n",
    "#     df['price_std_t60'] = df_grpby_id_sell_price.transform(lambda x: x.rolling(PRICE_WINDOW).std()).astype(np.float16)\n",
    "#     df['price_mean_t60'] = df_grpby_id_sell_price.transform(lambda x: x.rolling(PRICE_WINDOW).mean()).astype(np.float16)\n",
    "\n",
    "#     df['price_momentum_t60'] = (df['sell_price'] / df['price_mean_t60']).astype(np.float16)\n",
    "    df['price_mean_t60'] = df[['id','sell_price']].groupby([\"id\"])[\"sell_price\"].transform(lambda x: x.rolling(60).mean()).astype(np.float16)\n",
    "    df['price_momentum_t60'] = (df['sell_price'] / df['price_mean_t60']).astype(np.float16)\n",
    "    \n",
    "    date_features = {\n",
    "        \n",
    "        \"wday\": \"weekday\",\n",
    "        \"woy\": \"weekofyear\",\n",
    "        \"month\": \"month\",\n",
    "        \"quarter\": \"quarter\",\n",
    "        \"year\": \"year\",\n",
    "        \"mday\": \"day\",\n",
    "#         \"ime\": \"is_month_end\",\n",
    "#         \"ims\": \"is_month_start\",\n",
    "    }\n",
    "    \n",
    "#     df.drop([\"d\", \"wm_yr_wk\", \"weekday\"], axis=1, inplace = True)\n",
    "    \n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in df.columns:\n",
    "            df[date_feat_name] = df[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            df[date_feat_name] = getattr(df[\"date\"].dt, date_feat_func).astype(\"int16\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "create_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace = True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce mem usage of created features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = reduce_mem_usage(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fit & Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data usage: {} GB'.format(data.memory_usage().sum() / 10**9))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_end_dt = datetime(2016, 3, 27)\n",
    "valid_end_dt = datetime(2016, 4, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cat_feats = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id'] + [\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"]\n",
    "useless_cols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\"]\n",
    "train_cols = data.columns[~data.columns.isin(useless_cols)]\n",
    "\n",
    "# Splitting train and validation by date (28 days before prediction horizon)\n",
    "# To drop na values only from training set\n",
    "# train = data.loc[data.date <= train_end_dt].dropna()\n",
    "# X_train = train[train_cols]\n",
    "# y_train = train[\"sales\"]\n",
    "# %xdel train\n",
    "# gc.collect()\n",
    "\n",
    "# X_valid= data.loc[(data.date > train_end_dt) & (data.date <= valid_end_dt), train_cols]\n",
    "# y_valid = data.loc[(data.date > train_end_dt) & (data.date <= valid_end_dt), \"sales\"]\n",
    "# train_data = lgb.Dataset(X_train, label = y_train, categorical_feature=cat_feats, free_raw_data=False)\n",
    "# valid_data = lgb.Dataset(X_valid, label = y_valid, categorical_feature=cat_feats, free_raw_data=False)\n",
    "\n",
    "\n",
    "# Random train-validation split\n",
    "X_train = data[train_cols]\n",
    "y_train = data[\"sales\"]\n",
    "\n",
    "np.random.seed(SEED)\n",
    "valid_inds = np.random.choice(X_train.index.values, 2_000_000, replace = False)\n",
    "train_inds = np.setdiff1d(X_train.index.values, valid_inds)\n",
    "\n",
    "train_data = lgb.Dataset(X_train.loc[train_inds] , label = y_train.loc[train_inds], \n",
    "                         categorical_feature=cat_feats, free_raw_data=False)\n",
    "valid_data = lgb.Dataset(X_train.loc[valid_inds], label = y_train.loc[valid_inds],\n",
    "                        categorical_feature=cat_feats, free_raw_data=False)\n",
    "del valid_inds, train_inds\n",
    "\n",
    "del data, X_train, y_train \n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"objective\" : \"poisson\",\n",
    "        \"metric\" :\"rmse\",\n",
    "        \"force_row_wise\" : True,\n",
    "        \"learning_rate\" : 0.075,\n",
    "#         \"sub_feature\" : 0.8,\n",
    "        \"sub_row\" : 0.8,\n",
    "        \"bagging_freq\" : 1,\n",
    "        'feature_fraction': 0.8,\n",
    "        \"lambda_l2\" : 0.1,\n",
    "#         \"nthread\" : 4\n",
    "        'verbosity': 1,\n",
    "        'num_iterations' : 1200,\n",
    "        'num_leaves': 2**7-1,\n",
    "        \"min_data_in_leaf\": 2**7-1,\n",
    "        'early_stopping_rounds': 125,\n",
    "        'seed': SEED,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "m_lgb = lgb.train(params, train_data, valid_sets = [train_data, valid_data], \n",
    "                  verbose_eval=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('say \"Training complete\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_lgb.save_model(\"model.lgb\")\n",
    "#m_lgb = lgb.Booster(model_file='model.lgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\"Value\": m_lgb.feature_importance(), \"Feature\": m_lgb.feature_name()}) \\\n",
    "                    .sort_values(by=\"Value\", ascending=False)\n",
    "\n",
    "# Change size of the plot, so we can see all features\n",
    "fig_dims = (10, 14)\n",
    "fig, ax = plt.subplots(figsize=fig_dims)\n",
    "\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", ax=ax, data=feature_importance)\n",
    "plt.title('LightGBM Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection of features with zero-importance\n",
    "zero_features = list(feature_importance[feature_importance['Value'] == 0]['Feature'])\n",
    "print('\\nThere are {} features with 0.0 importance'.format(len(zero_features)))\n",
    "print(zero_features)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "tdata = pd.read_pickle(f'{DATA_GRID_INPUT_DIR}/m5_data_test_model2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_features_for_test(df, day):\n",
    "    # create lag feaures just for single day (faster)\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_t{lag}\" for lag in lags]\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        df.loc[df.date == day, lag_col] = df.loc[df.date ==day-timedelta(days=lag), 'sales'].values  # !!! main\n",
    "\n",
    "    windows = [7, 28]\n",
    "    for window in windows:\n",
    "        for lag in lags:\n",
    "            df_window = df[(df.date <= day-timedelta(days=lag)) & (df.date > day-timedelta(days=lag+window))]\n",
    "            df_window_grouped = df_window.groupby(\"id\").agg({'sales':'mean'}).reindex(df.loc[df.date==day,'id'])\n",
    "            df.loc[df.date == day,f\"rmean_{lag}_{window}\"] = df_window_grouped.sales.values     \n",
    "    \n",
    "    df['price_mean_t60'] = df.groupby([\"id\"])[\"sell_price\"].transform(lambda x: x.rolling(60).mean()).astype(np.float16)\n",
    "    df['price_momentum_t60'] = (df['sell_price'] / df['price_mean_t60']).astype(np.float16)\n",
    "\n",
    "    \n",
    "## Creating features for test data\n",
    "def create_date_features_for_test(df):\n",
    "    # copy of the code from `create_df()` above\n",
    "    date_features = {\n",
    "        \"wday\": \"weekday\",\n",
    "        \"woy\": \"weekofyear\",\n",
    "        \"month\": \"month\",\n",
    "        \"quarter\": \"quarter\",\n",
    "        \"year\": \"year\",\n",
    "        \"mday\": \"day\",\n",
    "    }\n",
    "\n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in df.columns:\n",
    "            df[date_feat_name] = df[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            df[date_feat_name] = getattr(\n",
    "                df[\"date\"].dt, date_feat_func).astype(\"int16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_date_features_for_test(tdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(0, 28):\n",
    "    day = FIRST_PRED_DAY + timedelta(days=i)\n",
    "    print(i, day)\n",
    "    tst = tdata[(tdata.date >= day - timedelta(days=max_lags)) & (tdata.date <= day)].copy()\n",
    "    create_lag_features_for_test(tst, day)\n",
    "    tst = tst.loc[tst.date == day, train_cols]\n",
    "    tdata.loc[tdata.date == day, \"sales\"] = 1.03*m_lgb.predict(tst) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('say \"Prediction complete\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata.loc[(tdata.date >= FIRST_PRED_DAY) & (tdata.sales > 2)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tdata_sub = tdata.loc[tdata.date >= FIRST_PRED_DAY, [\"id\", \"sales\"]].copy()\n",
    "tdata_sub.loc[tdata.date >= FIRST_PRED_DAY+ timedelta(days=h), \"id\"] = tdata_sub.loc[tdata.date >= FIRST_PRED_DAY+timedelta(days=h), \n",
    "                                                                     \"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "tdata_sub[\"F\"] = [f\"F{rank}\" for rank in tdata_sub.groupby(\"id\")[\"id\"].cumcount()+1]\n",
    "tdata_sub = tdata_sub.set_index([\"id\", \"F\" ]).unstack()[\"sales\"][[f\"F{i}\" for i in range(1,29)]].reset_index()\n",
    "tdata_sub.fillna(0., inplace = True)\n",
    "\n",
    "# kyakovlev magic trick\n",
    "# for i in range(1,29):\n",
    "#     tdata_sub['F'+str(i)] *= 1.03\n",
    "\n",
    "tdata_sub.to_csv(\"submission.csv\",index=False)\n",
    "tdata_sub.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
